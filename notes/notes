Fri 19 Jun 2020 02:34:11 AM EDT
{
  So how will it work?
  Right now the Abstractors are just fns in app main.
  Now app main will fill in the abs data structures, 
  hand them to the library, and say "Go!"

  OK! right away, I have something interesting with
  threshold.
  It would be *really nice* if it could refer back to the 
  original image, and apply its threshold to that, in order
  to do a visualization of the results.

  How?

  By
    1. having a 'genealogy' of abstractions that its abstraction
       came from.
         i.e. the image sensor adds a stamp to its post message
              that says "image" "1"
              hmmm.
              Just names like that do not imply ordering, so 
              things all have to know which comes first.
              And what if the order is data-dependent.

         OK, so we need a 'path' :
            { 
              {"image", "1"},
              {"histogram", "1"},
              ...
            }

         Every Abstractor assigns a unique ID to each of its 
         output abstractions, and appends this 'atep' to the end of
         the 'path'.
         So if anybody wants to, they can see where this abstraction came from.

         AND THEN THE BULLETIN BOARD STORES THEM ALL.
}


Thu 18 Jun 2020 05:10:23 AM EDT
{
  OK!
  Here's a concept.
  An Abstractor is not a function, it's a data structure.
    fp ( os.Stdout, "MDEBUG new: %d saved: %d\n", new_energy, saved_energy )

  It contains fn pointers to all the fns that constitute the Abstractor, 
  and each fn gets a pointer to that struct as its first arg.
  In this way, a facility like the logger can tell the Abstractor
  to visualize its results -- but control (with args) where the jpg
  files go.

  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

  How about a logger?
  I keep making debug print statements as I write individual 
  Abstractors, but the whole idea is that eventually the activity 
  between Abstractors will become too complex to follow -- without
  a lot of help. So ... how about a logger that all Abstractors 
  can send notes to about what they are doing.

  And ... what does it do? For now, just timestamp everything 
  and write it to a file.

  And it makes everything into a single stream.
}




Tue 16 Jun 2020 12:23:22 AM EDT
{
  For now, sensor will just be on a fixed timer.
  RIGHT NOW -- it can generate names of the frame images.
  It does not start until app receives reply from Tach saying
  that the topic has been created.

  NEXT -- read the image, turn it into a pixel array,
          and post to the topic!
  

  By the way -- 
  note on breaking video info frames:

        ffmpeg -i VID00004.MP4 -r 30 -f image2  ./1/monday_road_trip-%05d.tif
  
  And combining frames into video:

        ffmpeg -f image2 -i test.%04d.png -r 10  foo.avi

}



Fri 08 May 2020 05:16:39 AM EDT
{
  How to do the actual sensor?
  Give it a channel from main that it listens to,
  and fires when it hears the command.
}


Wed 06 May 2020 02:32:21 AM EDT
{
  The vision now is something like this:

  There are two levels of Abstractors in Tachyon.
  The lower is called the Sensorium.
  It is a collection of Abstractors that is pulsed by the
  Sensor. The Sensor produces an image, and the rest of the 
  Sensorium runs automatically, driven by a fixed pattern of
  subscriptions to topics.

  Right now I think the pattern is this:

  image --> histogram --> threshold --> binary_image --> connected_components

  It need not be linear -- could be branching -- but this 
  one is linear so far.

  How is the imaging Sensor driven?
  Probably simply pulsed once from main() for now.

  But when we get to connected_components something new happens.
  There is an Abstractor waiting on that Topic that has the 
  ability to launch more Abstractors!
  And these are the first examples of non-Sensorium, 'cognitive' 
  Abstractors. All Abstractors from this level higher will shares this
  property: that they are not hard-wired to specific Topics
  and do not pulse in rhythm with the frame-times of the Sensor.

  Cognitive Abstractors will require the ability to browse the timeline 
  of postings to all Topics, probably on a bulletin board.
  From this level up, Abstractors will operate in a more complex way,
  spawning each other, advertising for inputs, maybe some form of
  competition.

  But the first step is just to get that initial Abstractor to 
  spawn news ones: one for each bright component it sees in 
  connected_components.

  These first 'cognitive' Abstractor will be responsible for 
  following each bright connected component as it travels through
  the image.
}





Mon 04 May 2020 02:04:51 AM EDT
{
  ok how about this....
  there is an abs that can launch others.
  it looks at things -- coming to it in a normal feed

  OK -- how about this :


    * there is a single BB

    * they browse - BB helps

    * there is a single launcher that guarantees only
      one to a region-or-whatever AT THE START.
    
    * AFter that, they compete - based on highest certainty.

    -----------------------------------------------------

    ok -- how do advertisements work ?

      * controlled vocab

      * inputs, and outputs

      * standard window def'n and whatever else

      * things can work on more specific versions
}





Sun 03 May 2020 05:33:00 AM EDT
{
  
  OK!
  SO -- 
  THERE IS A DIFFERENT WAY OF SUBSCRIBING TO A TOPIC.
  THE TOPIC KEEPS HISTORY.
  THIS SUBSCRIPTION JUST WANTS A NOTICE WHEN YOU HAVE 
  TWO FRAMES -- EACH NEW FRAME 2 AND UP, IT WANTS TO KNOW.

  AND THEN IT COMES AND BROWSES!!!

  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^


  But how do multi-frame abstractors work?

    * How do you prevent multiple Abstractors 
      fromworking on the same thing?

 
   ? They can see all history, because the Topics 
     also store everything.

   ? They can mark messages somehow, to indicate ownership.
  
   ? If another Abstractor of the same type attempts to
     mark a message, it can't.

   * Those marks are serialized by sending them as msgs to 
     the owning Topic.

   * So something is browsing history of a given topic.

}





Sat 02 May 2020 11:05:45 AM EDT
{
  Big bright object.
  Track it!
  Image --> Brightness Image --> Gray Histogram --> 
    Easy Threshold --> Region Finder --> Multi-Frame Tracker !!!

  Track intermittent objects !!!
}
